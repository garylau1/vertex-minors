{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garylau1/vertex-minors/blob/master/YK_Practical_Week_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTEnti9mxZtN"
      },
      "source": [
        "# 0. Text encoding\n",
        "\n",
        "There is a file called \"story-cp1252.txt\" you will use in this practical. It has the special open-quote and close-quote characters from code page 1252.\n",
        "\n",
        "Open it up in two different programs that will render it differently, and take a screenshot of each.\n",
        "\n",
        "Be creative! Suggestions include Windows Notepad and the more command in a CMD prompt window. On OSX, Microsoft Word (if you specify Windows Latin 1 as the encoding) can render the quotes; most other programs won't.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fbGKe-zxZtQ"
      },
      "source": [
        "*This cell is where you can put the screenshots*\n",
        "encoding to tehcique repreented by computer teqique\n",
        "\n",
        "different hardware support diff techique-diffe teqhieu are encoding\n",
        "\n",
        "some support max system but not other\n",
        "\n",
        "\n",
        "\n",
        "in max it might completely clashed\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "move to the ode stuff"
      ],
      "metadata": {
        "id": "-Tr5SeRiyku-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRdYZaRhxZtR"
      },
      "source": [
        "### Crasher\n",
        "\n",
        "The following cell will fail with a unicode exception. Fix it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "bfpBwRcjxZtR",
        "outputId": "291e3445-8c6b-4dae-a46a-5009cfdbddb9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0x93 in position 376: invalid start byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4f02d3abcee9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'story-cp1252.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x93 in position 376: invalid start byte"
          ]
        }
      ],
      "source": [
        "#the character in this file not suppoered by fault\n",
        "#diferent dataset\n",
        "#encoding techique\n",
        "#ow to open speicifc one in some other encoding suppoered by oter system\n",
        "with open('story-cp1252.txt') as f:\n",
        "    f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN0JfKvrxZtS"
      },
      "source": [
        "### Copying\n",
        "\n",
        "Make a copy of story-cp1252.txt in **utf-8 format** and then look at it using some other tool on your computer. (e.g.\n",
        "Windows notepad)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "t1t7vxEexZtS"
      },
      "outputs": [],
      "source": [
        "# this is where to put your code #copy into new file utff 8\n",
        "\n",
        "\n",
        "with open('story-cp1252.txt',encoding=\"cp1252\") as f:\n",
        "  #not speicif w it assumed it is read #if file is already there-if not creatd-cratea new file and do it\n",
        "  #copy content from f to g\n",
        "    with open('st1ory-utf8.txt',\"w\",encoding=\"utf-8\") as g:\n",
        "        g.write(f.read()) #copy the from file f into file g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dvj2Qz4xZtT"
      },
      "source": [
        "Make a copy of story-cp1252.txt in **utf-16 format**. Check the size of it in bytes. If you are using Linux or OSX, the UTF-16 file may look like it is corrupted. On Windows it will open normally."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('story-cp1252.txt',encoding=\"cp1252\") as f:\n",
        "  with open('16666.txt',\"w\",encoding=\"utf-16\") as q:\n",
        "        q.write(f.read()) #copy the from file f into file g\n",
        "\n",
        "#speiciifc the encoding as utf 16"
      ],
      "metadata": {
        "id": "QmllHK-wzOQN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVwvOruXxZtT"
      },
      "outputs": [],
      "source": [
        "# this is where to put your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CRsVppQxZtT"
      },
      "source": [
        "# 1. Simple Statistics and NLTK\n",
        "\n",
        "The following exercises use a portion of the Gutenberg corpus that is stored in the corpus dataset of NLTK. [The Project Gutenberg](http://www.gutenberg.org/) is a large collection of electronic books that are out of copyright. These books are free to download for reading, or for our case, for doing a little of corpus analysis.\n",
        "\n",
        "To obtain the list of files of NLTK's Gutenberg corpus, type the following commands:\n",
        "\n",
        "#file in difffernt format\n",
        "\n",
        "#plain text utf-8  particular format\n",
        "#HTML-oteher download option\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjsnmOsAxZtU",
        "outputId": "8a700a8c-1926-4e05-a10e-404934221aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')    #call dataset corpus -mean dataset\n",
        "nltk.corpus.gutenberg.fileids()\n",
        "\n",
        "#cqaled function id\n",
        "#read the file name on NLP cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPAXkZEVxZtU"
      },
      "source": [
        "To obtain all words in the entire Gutenberg corpus of NLTK, type the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2E2ZYUyxZtU",
        "outputId": "3f12e36d-1109-4754-8cfc-47ce00d8e75c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "gutenbergwords = nltk.corpus.gutenberg.words()\n",
        "gutenbergwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5PKiRuJxZtU"
      },
      "source": [
        "Now you can find the total number of words, and the first 10 words (do not attempt to display all the words or your computer will freeze!):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OegqKTA1xZtV",
        "outputId": "cf2659f9-6b80-40f2-c77c-cdfb191d5d8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "len(gutenbergwords)\n",
        "\n",
        "len(nltk.corpus.gutenberg.fileids())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhAJB4iKxZtV",
        "outputId": "c4036d60-b365-4b55-ac7d-342cc712c7c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[',\n",
              " 'Emma',\n",
              " 'by',\n",
              " 'Jane',\n",
              " 'Austen',\n",
              " '1816',\n",
              " ']',\n",
              " 'VOLUME',\n",
              " 'I',\n",
              " 'CHAPTER',\n",
              " 'I',\n",
              " 'Emma',\n",
              " 'Woodhouse',\n",
              " ',',\n",
              " 'handsome',\n",
              " ',',\n",
              " 'clever',\n",
              " ',',\n",
              " 'and',\n",
              " 'rich',\n",
              " ',',\n",
              " 'with',\n",
              " 'a',\n",
              " 'comfortable',\n",
              " 'home',\n",
              " 'and',\n",
              " 'happy',\n",
              " 'disposition',\n",
              " ',',\n",
              " 'seemed']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "gutenbergwords[:30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwfMZpRaxZtV"
      },
      "source": [
        "You can also find the words of just a selection of documents, as shown below. For more details of what information you can extract from this corpus, read the \"Gutenberg corpus\" section of the [NLTK book chapter 2](http://www.nltk.org/book_1ed/ch02.html), section 2.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWm7LcH7xZtV",
        "outputId": "cbaf2559-4ead-4d7d-dcb4-8da17f7a7e71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192427"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
        "len(emma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72W1teM_xZtV",
        "outputId": "102c52d5-44e3-432f-b843-cbeb874fed12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "emma[:10]\n",
        "\n",
        "#seperated by space-space is not token in default sometimes not work for other lanaguage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNMtwnlexZtV"
      },
      "source": [
        "As we have seen in the lectures, we can use Python's `collections.Counter` to find the most frequent words of a document from NLTK's Gutenberg collection. Below you can see how you can find the 5 most frequent words of the word list stored in the variable `emma`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9CVWaKRxZtV",
        "outputId": "8d4520ca-edaf-455a-cc0d-afb9b05a96bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', 11454), ('.', 6928), ('to', 5183), ('the', 4844), ('and', 4672), ('of', 4279), ('I', 3178), ('a', 3004), ('was', 2385), ('her', 2381), (';', 2199), ('it', 2128), ('in', 2118), ('not', 2101), ('\"', 2004), ('be', 1970), ('she', 1778), ('that', 1730), ('you', 1677), ('had', 1606)]\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "emma_counter = collections.Counter(emma)\n",
        "print(emma_counter.most_common(20))\n",
        "\n",
        "#make decision-those wods should not as valid\n",
        "# jane austen seperated-can decied differenly diffeent version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqvMObP0xZtW"
      },
      "source": [
        "### Exercise 1.1\n",
        "*Write Python code that prints the 10 most frequent words in each of the documents of the Gutenberg corpus. Can you identify any similarities among these list of most frequent words?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVdCTjtGxZtW",
        "outputId": "c59cad45-5002-4517-8c9e-c79fe130cf1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "austen-emma.txt\n",
            "[(',', 11454), ('.', 6928), ('to', 5183), ('the', 4844), ('and', 4672), ('of', 4279), ('I', 3178), ('a', 3004), ('was', 2385), ('her', 2381)]\n",
            "austen-persuasion.txt\n",
            "[(',', 6750), ('the', 3120), ('to', 2775), ('.', 2741), ('and', 2739), ('of', 2564), ('a', 1529), ('in', 1346), ('was', 1330), (';', 1290)]\n",
            "austen-sense.txt\n",
            "[(',', 9397), ('to', 4063), ('.', 3975), ('the', 3861), ('of', 3565), ('and', 3350), ('her', 2436), ('a', 2043), ('I', 2004), ('in', 1904)]\n",
            "bible-kjv.txt\n",
            "[(',', 70509), ('the', 62103), (':', 43766), ('and', 38847), ('of', 34480), ('.', 26160), ('to', 13396), ('And', 12846), ('that', 12576), ('in', 12331)]\n",
            "blake-poems.txt\n",
            "[(',', 680), ('the', 351), ('.', 201), ('And', 176), ('and', 169), ('of', 131), ('I', 130), ('in', 116), ('a', 108), (\"'\", 104)]\n",
            "bryant-stories.txt\n",
            "[(',', 3481), ('the', 3086), ('and', 1873), ('.', 1817), ('to', 1165), ('a', 988), ('\"', 900), ('he', 872), ('of', 801), ('was', 706)]\n",
            "burgess-busterbrown.txt\n",
            "[('.', 823), (',', 822), ('the', 639), ('he', 562), ('and', 484), ('to', 426), (\"'\", 401), ('of', 326), ('that', 285), ('a', 275)]\n",
            "carroll-alice.txt\n",
            "[(',', 1993), (\"'\", 1731), ('the', 1527), ('and', 802), ('.', 764), ('to', 725), ('a', 615), ('I', 543), ('it', 527), ('she', 509)]\n",
            "chesterton-ball.txt\n",
            "[(',', 4547), ('the', 4523), ('.', 3589), ('of', 2529), ('and', 2488), ('a', 2184), ('\"', 1751), ('to', 1558), ('in', 1355), ('that', 1120)]\n",
            "chesterton-brown.txt\n",
            "[('the', 4321), (',', 4069), ('.', 2784), ('of', 2087), ('and', 2074), ('a', 2074), ('\"', 1461), ('to', 1378), ('in', 1205), ('was', 1141)]\n",
            "chesterton-thursday.txt\n",
            "[(',', 3488), ('the', 3291), ('.', 2717), ('a', 1713), ('of', 1710), ('and', 1568), ('\"', 1336), ('to', 1045), ('in', 888), ('I', 885)]\n",
            "edgeworth-parents.txt\n",
            "[(',', 15219), ('the', 7149), ('.', 6945), ('to', 5150), ('and', 4769), ('\"', 3880), ('of', 3730), ('I', 3656), (\"'\", 3293), ('a', 3017)]\n",
            "melville-moby_dick.txt\n",
            "[(',', 18713), ('the', 13721), ('.', 6862), ('of', 6536), ('and', 6024), ('a', 4569), ('to', 4542), (';', 4072), ('in', 3916), ('that', 2982)]\n",
            "milton-paradise.txt\n",
            "[(',', 10198), ('and', 2799), ('the', 2505), (';', 2317), ('to', 1758), ('of', 1486), ('.', 1254), ('in', 1083), ('his', 986), ('with', 876)]\n",
            "shakespeare-caesar.txt\n",
            "[(',', 2204), ('.', 1296), ('I', 531), ('the', 502), (':', 499), ('and', 409), (\"'\", 384), ('to', 370), ('you', 342), ('of', 336)]\n",
            "shakespeare-hamlet.txt\n",
            "[(',', 2892), ('.', 1886), ('the', 860), (\"'\", 729), ('and', 606), ('of', 576), ('to', 576), (':', 565), ('I', 553), ('you', 479)]\n",
            "shakespeare-macbeth.txt\n",
            "[(',', 1962), ('.', 1235), (\"'\", 637), ('the', 531), (':', 477), ('and', 376), ('I', 333), ('of', 315), ('to', 311), ('?', 241)]\n",
            "whitman-leaves.txt\n",
            "[(',', 17713), ('the', 8814), ('and', 4797), ('of', 4127), ('I', 2932), (\"'\", 2362), ('to', 1930), ('-', 1774), ('.', 1769), ('in', 1714)]\n"
          ]
        }
      ],
      "source": [
        "for i in nltk.corpus.gutenberg.fileids():\n",
        "  emm1a = nltk.corpus.gutenberg.words(i)\n",
        "  print (i)\n",
        "  emma_counter1 = collections.Counter(emm1a)\n",
        "  print(emma_counter1.most_common(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeYNEPmQxZtW"
      },
      "source": [
        "### Exercise 1.2\n",
        "*Find the unique words with length of more than 17 characters in the complete Gutenberg corpus.*\n",
        "\n",
        "*Hint: to find the distinct items of a Python list you can convert it into a set:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoB7vXhYxZtW"
      },
      "outputs": [],
      "source": [
        "my_list = ['a','b','c','a','c']\n",
        "my_set = set(my_list)\n",
        "print(my_set)\n",
        "print(len(my_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06KaU3zVxZtW"
      },
      "outputs": [],
      "source": [
        "# put your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qz4_S7WxZtW"
      },
      "source": [
        "### Exercise 1.3\n",
        "*Find the words that are longer than 5 characters and occur more than 2000 times in the complete Gutenberg corpus.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkYqxMX_xZtW"
      },
      "outputs": [],
      "source": [
        "# put your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iGkAn-2xZtX"
      },
      "source": [
        "### Exercise 1.4\n",
        "*Find the average number of words in the documents of the NLTK Gutenberg corpus.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3LTrizSxZtX"
      },
      "outputs": [],
      "source": [
        "# put your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkb7-apExZtX"
      },
      "source": [
        "### (Optional) Exercise 1.5\n",
        "*Find the Gutenberg document that has the longest average word length.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ddOqiGgxZtX"
      },
      "outputs": [],
      "source": [
        "# put your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tXlAdMNxZtX"
      },
      "source": [
        "### Exercise 1.6\n",
        "*Find the 10 most frequent bigrams in the entire Gutenberg corpus.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAapKyYDxZtX"
      },
      "outputs": [],
      "source": [
        "# put your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh1vbeSmxZtY"
      },
      "source": [
        "### Exercise 1.7\n",
        "*Find the most frequent bigram that begins with \"Moby\" in Herman Melville's \"Moby Dick\".*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u_wKNFuxZtY"
      },
      "outputs": [],
      "source": [
        "# put your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1h0CpjfxZtY"
      },
      "source": [
        "# 2. Text Preprocessing with NLTK\n",
        "The following exercises will ask questions about tokens, stems, and parts of speech.\n",
        "\n",
        "### Exercise 2.1\n",
        "*What is the sentence with the largest number of tokens in Austen's \"Emma\"?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mdKBGU5xZtb"
      },
      "outputs": [],
      "source": [
        "# put your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZZK18UQxZtb"
      },
      "source": [
        "### Exercise 2.2\n",
        "*What are the 5 most frequent parts of speech in Austen's \"Emma\"? Use the universal tag set*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q9IW_zcxZtb"
      },
      "outputs": [],
      "source": [
        "# put your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu2F1FXnxZti"
      },
      "source": [
        "### Exercise 2.3\n",
        "*What is the number of distinct stems in Austen's \"Emma\"?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "153EFyQExZtj"
      },
      "outputs": [],
      "source": [
        "# put your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chvmJ_xlxZtj"
      },
      "source": [
        "### (Optional) Exercise 2.4\n",
        "*What is the most ambiguous stem in Austen's \"Emma\"? (meaning, which stem in Austen's \"Emma\" is realised in the largest number of distinct tokens?)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2uDG_rjxZtj"
      },
      "outputs": [],
      "source": [
        "# put your code here"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "interpreter": {
      "hash": "a7b63e7410c98f344f02082f10d790581d1dba1eeb1c8fe30f342f6109f0429e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('comp3220': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}