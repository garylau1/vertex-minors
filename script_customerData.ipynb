{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garylau1/vertex-minors/blob/master/script_customerData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b864oO6hpTqX"
      },
      "source": [
        "In this task we would do a classification in Brain tumor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile path_loader.py\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "out_path=Path(\"out_model_set\")\n",
        "os.makedirs(out_path,exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "Imagepath=(\"/content/Brain-Tumor-Classification-DataSet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrR8mBbuLLMV",
        "outputId": "4d22e7c8-cac5-4f08-c5d6-ef295f076b9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing path_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python path_loader.py"
      ],
      "metadata": {
        "id": "xvEXqUnRr9UM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile out_model_set/data_creator.py\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def find_classes(dict1):\n",
        "  \"\"\"find the class fikder bane\"\"\"\n",
        "\n",
        "  found=sorted([entry1.name for entry1 in list(os.scandir(dict1))if entry1.is_dir()])\n",
        "  if not found:\n",
        "      raise  FileNotFoundError(f\"no such class1111 in {dict1}\")\n",
        "\n",
        "  class_index={class_name: i for i,class_name in enumerate(found)}\n",
        "  return found,class_index\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class customdataset(Dataset):\n",
        "\n",
        "  def find_classes(self,dict1):\n",
        "\n",
        "    found=sorted([entry1.name for entry1 in list(os.scandir(dict1))if entry1.is_dir()])\n",
        "    #found=[entry1.name for entry1 in list(os.scandir(dict1))if entry1.is_dir()]\n",
        "    if not found:\n",
        "      raise  FileNotFoundError(f\"no such class1111 in {dict1}\")\n",
        "\n",
        "    class_index={class_name: i for i,class_name in enumerate(found)}\n",
        "    return found,class_index\n",
        "\n",
        "\n",
        "  def __init__(self,target_folder,transform=None):\n",
        "    #self.targetpath=list(target_folder.glob(\"*/*.jpg\"))\n",
        "    self.targetpath=sorted(list(pathlib.Path(target_folder).glob(\"*/*.jpg\")))\n",
        "    self.transform=transform\n",
        "    self.classes,self.class_to_idx=self.find_classes(target_folder)\n",
        "\n",
        "    self.transform_2=transforms.Compose(\n",
        "    [transforms.Resize((224,224)),transforms.RandomHorizontalFlip(p=0.5),transforms.ToTensor()])\n",
        "\n",
        "\n",
        "  def load_image(self,index):\n",
        "      return (Image.open(self.targetpath[index]))\n",
        "  def __len__(self):\n",
        "      a=self.targetpath\n",
        "      return len(a)\n",
        "\n",
        "  def __getitem__(self,inx):\n",
        "\n",
        "    load=(self.load_image(inx))\n",
        "    name=self.targetpath[inx].parent.name\n",
        "    class_index=self.class_to_idx[name]\n",
        "\n",
        "\n",
        "    if self.transform:\n",
        "      return self.transform(load),class_index\n",
        "    else:\n",
        "      return self.transform_2(load),class_index\n",
        "\n",
        "\n",
        "data_transform_aug=transforms.Compose([transforms.Resize((228,228)),transforms.TrivialAugmentWide(num_magnitude_bins=31),transforms.ToTensor()])\n",
        "\n",
        "data_transform_simple=transforms.Compose(\n",
        "    [transforms.Resize((228,228)),transforms.ToTensor()])\n",
        "\n",
        "def customdataset_loader(batchs,train_dir,test_dir,transform=data_transform_aug,transform2=data_transform_simple):\n",
        "  train_dataset=customdataset(train_dir,data_transform_aug)\n",
        "  test_dataset=customdataset(test_dir,data_transform_simple)\n",
        "\n",
        "  class_num=len(train_dataset.classes)\n",
        "\n",
        "  train_loader_simple=DataLoader(dataset=train_dataset,batch_size=batchs,shuffle=True,num_workers=os.cpu_count())\n",
        "\n",
        "  test_loader_simple=DataLoader(dataset=test_dataset,batch_size=batchs,shuffle=False,num_workers=os.cpu_count())\n",
        "\n",
        "  return train_loader_simple,test_loader_simple,len(train_dataset.classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkLyhAwwU6_s",
        "outputId": "4d6bb1d2-c06a-4163-b296-c70eaa3ca59e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing out_model_set/data_creator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3wmMFDgie9Pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcabcd94-6594-4b17-c554-76734f13e743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/out_model_set/model_creator.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/out_model_set/model_creator.py\n",
        "\n",
        "from torch import nn\n",
        "class tinygvv(nn.Module):\n",
        "  def __init__(self,in_fea,out_fea,hidden1,hidden2,hidden3,hidden4,hidden5,hidden6):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer1=nn.Sequential(nn.Conv2d(in_channels=in_fea,out_channels=hidden1,kernel_size=3,stride=1,padding=0),\n",
        "                              nn.ReLU(),nn.Conv2d(in_channels=hidden1,out_channels=hidden2,kernel_size=3,stride=1,padding=0),nn.ReLU(),nn.MaxPool2d(2))\n",
        "\n",
        "    self.layer2=nn.Sequential(nn.Conv2d(in_channels=hidden2,out_channels=hidden3,kernel_size=3,stride=1,padding=0),\n",
        "                              nn.ReLU(),nn.Conv2d(in_channels=hidden3,out_channels=hidden4,kernel_size=3,stride=1,padding=0),nn.ReLU(),nn.MaxPool2d(2))\n",
        "\n",
        "    self.layer3=nn.Sequential(nn.Conv2d(in_channels=hidden4,out_channels=hidden5,kernel_size=3,stride=1,padding=0),\n",
        "                              nn.ReLU(),nn.Conv2d(in_channels=hidden5,out_channels=hidden6,kernel_size=3,stride=1,padding=0),nn.ReLU(),nn.MaxPool2d(2))\n",
        "\n",
        "    self.layer4=nn.Sequential(nn.Flatten(),nn.Linear(5000,out_fea)) #turn into feature vetcors size\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layer4(self.layer3(self.layer2(self.layer1(x))))   #not go back to computation not in one hint\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9Ur8fnB5Bzao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7c2b2f-c940-4c88-ec1e-51d2c1245e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/out_model_set/train_creator.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/out_model_set/train_creator.py\n",
        "#train_loader=DataLoader(dataset=train_dataset,batch_size=32,num_workers=2,shuffle=True)\n",
        "#test_loader=DataLoader(dataset=test_data,batch_size=32,num_workers=2,shuffle=False)\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "\n",
        "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def train_step(model,data_loader,lost_fn,optimizer,device=device):\n",
        "  model.train()\n",
        "  loss=0\n",
        "  acc=0\n",
        "  for batch,(X,y) in enumerate(data_loader):\n",
        "    X=X.to(device)\n",
        "    y=y.to(device)\n",
        "    y_logit=model(X)\n",
        "\n",
        "    y_label=torch.softmax(y_logit,-1).argmax(-1)\n",
        "\n",
        "    loss_ff=lost_fn(y_logit,y)\n",
        "\n",
        "    loss=loss+loss_ff.item()\n",
        "\n",
        "    acc=acc+torch.sum(y_label==y).item()/len(y)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss_ff.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  loss=loss/len(data_loader)\n",
        "\n",
        "  acc=acc/len(data_loader)\n",
        "\n",
        "  return loss,acc\n",
        "\n",
        "def test_step(model,data_loader,lost_fn,device=device):\n",
        "  model.eval()\n",
        "  loss=0\n",
        "  acc=0\n",
        "  with torch.inference_mode():\n",
        "    for batch,(X,y) in enumerate(data_loader):\n",
        "      X=X.to(device)\n",
        "      y=y.to(device)\n",
        "      y_logit=model(X)\n",
        "\n",
        "      y_label=torch.softmax(y_logit,-1).argmax(-1)\n",
        "\n",
        "      loss_ff=lost_fn(y_logit,y)\n",
        "      loss=loss+loss_ff.item()\n",
        "\n",
        "      acc=acc+torch.sum(y_label==y).item()/len(y)\n",
        "\n",
        "    loss=loss/len(data_loader)\n",
        "\n",
        "    acc=acc/len(data_loader)\n",
        "\n",
        "  return loss,acc\n",
        "\n",
        "\n",
        "\n",
        "def model_fit(model,epochs,train_loaders,test_loaders,loss_fun,optimizer,device=device):\n",
        "\n",
        "  training_loss=[]\n",
        "  training_acc=[]\n",
        "  testing_loss=[]\n",
        "  testing_acc=[]\n",
        "\n",
        "  for i in range(epochs):\n",
        "    a,b=train_step(model,train_loaders,loss_fun,optimizer,device=device)\n",
        "\n",
        "\n",
        "    c,d=test_step(model,test_loaders,loss_fun,device=device)\n",
        "    training_loss.append(a)\n",
        "    training_acc.append(b)\n",
        "    testing_loss.append(c)\n",
        "    testing_acc.append(d)\n",
        "    print(f\"training_loss : {a}, training_acc : {b},testing_loss : {c}, testing_acc : {d}\")\n",
        "\n",
        "  return {\"training_loss\": training_loss,\"training acc\": training_acc,\"testing_loss\": testing_loss,\"testing acc\": testing_acc}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile out_model_set/final_train.py\n",
        "#train_loader=DataLoader(dataset=train_dataset,batch_size=32,num_workers=2,shuffle=True)\n",
        "#test_loader=DataLoader(dataset=test_data,batch_size=32,num_workers=2,shuffle=False)\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "import data_creator,model_creator,train_creator\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from torch import nn\n",
        "import argparse\n",
        "parser = argparse.ArgumentParser(description=\"This is example of argparse!\")\n",
        "parser.add_argument('--BATCH_size',default=32,type=int)\n",
        "parser.add_argument(\"--hidden_unit1\",default=256,type=int)\n",
        "parser.add_argument(\"--hidden_unit2\",default=128,type=int)\n",
        "parser.add_argument(\"--hidden_unit3\",default=64,type=int)\n",
        "parser.add_argument(\"--hidden_unit4\",default=32,type=int)\n",
        "parser.add_argument(\"--hidden_unit5\",default=16,type=int)\n",
        "\n",
        "parser.add_argument('--NUM_EPOCHS',default=5,type=int)\n",
        "parser.add_argument('--Learning_rate',default=0.001,type=float)\n",
        "parser.add_argument(\"--imagepath\",default=\"/content/Brain-Tumor-Classification-DataSet\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "imagepath=args.imagepath\n",
        "hidden_unit1=args.hidden_unit1\n",
        "hidden_unit2=args.hidden_unit2\n",
        "hidden_unit3=args.hidden_unit3\n",
        "hidden_unit4=args.hidden_unit4\n",
        "hidden_unit5=args.hidden_unit5\n",
        "batch=args.BATCH_size\n",
        "NUM_EPOCHS =args.NUM_EPOCHS\n",
        "Learning_rate=args.Learning_rate\n",
        "\n",
        "imagepath=Path(imagepath)\n",
        "\n",
        "train_dir=imagepath/\"Training\"\n",
        "test_dir=imagepath/\"Testing\"\n",
        "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_loader_simple,test_loader_simple,class_num=data_creator.customdataset_loader(batch,train_dir,test_dir)\n",
        "\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "model_0=model_creator.tinygvv(3,class_num,hidden_unit1,hidden_unit2,hidden_unit3,hidden_unit4,hidden_unit5,8).to(device)\n",
        "\n",
        "\n",
        "optimizer_0=torch.optim.Adam(model_0.parameters(), lr=Learning_rate)\n",
        "\n",
        "model_fit_1=train_creator.model_fit(model_0,NUM_EPOCHS,train_loader_simple,test_loader_simple,loss_fn,optimizer_0)\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Create models directory (if it doesn't already exist), see: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, # create parent directories if needed\n",
        "                 exist_ok=True # if models directory already exists, don't error\n",
        ")\n",
        "\n",
        "# Create model save path\n",
        "MODEL_NAME = \"MODEL_PATH222\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "\n",
        "torch.save(model_0.state_dict(),f=MODEL_SAVE_PATH)\n"
      ],
      "metadata": {
        "id": "8ZiDxExOWO00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd518821-9377-4bea-bef0-5d7da8b8e4d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing out_model_set/final_train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile open_test_2.py\n",
        "\n",
        "import requests\n",
        "request=requests.get('https://cdnintech.com/media/chapter/43882/1512345123/media/image3.png')\n",
        "#https://www.intechopen.com/chapters/43882\n",
        "#request=requests.get('https://cdn.the-scientist.com/assets/articleNo/70327/iImg/47139/glioblastoma-inline-l.webp')\n",
        "with open(\"/content/Brain-Tumor-Classification-DataSet/test_image2\", \"wb\") as f:\n",
        "  f.write(request.content)\n",
        "#import requests\n",
        "#import Image\n",
        "#Image.open(MODEL_PATH/\"test_image2\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3aJCwIhBAPK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ac2c84-0915-492a-d6be-9af04060a8dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing open_test_2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile out_model_set/final_pred.py\n",
        "\n",
        "\n",
        "from torchvision import  transforms\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import model_creator,data_creator\n",
        "\n",
        "import argparse\n",
        "parser = argparse.ArgumentParser(description=\"This is example of argparse!\")\n",
        "parser.add_argument('--imagepath',default=\"test_image2\")\n",
        "parser.add_argument(\"--hidden_unit1\",default=256,type=int)\n",
        "parser.add_argument(\"--hidden_unit2\",default=128,type=int)\n",
        "parser.add_argument(\"--hidden_unit3\",default=64,type=int)\n",
        "parser.add_argument(\"--hidden_unit4\",default=32,type=int)\n",
        "parser.add_argument(\"--hidden_unit5\",default=16,type=int)\n",
        "\n",
        "parser.add_argument('--NUM_EPOCHS',default=5,type=int)\n",
        "parser.add_argument('--Learning_rate',default=0.001,type=float)\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "imagepath=args.imagepath\n",
        "hidden_unit1=args.hidden_unit1\n",
        "hidden_unit2=args.hidden_unit2\n",
        "hidden_unit3=args.hidden_unit3\n",
        "hidden_unit4=args.hidden_unit4\n",
        "hidden_unit5=args.hidden_unit5\n",
        "\n",
        "def convertion_function(path0):\n",
        "\n",
        "  device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  newImagePath=Path(\"/content/Brain-Tumor-Classification-DataSet\")\n",
        "\n",
        "  custom_uni8=torchvision.io.read_image(newImagePath/path0)\n",
        "  custom_uni8=custom_uni8.type(torch.float).to(device)/255\n",
        "\n",
        "  return custom_uni8\n",
        "\n",
        "def custom_loader(path0=imagepath):\n",
        "\n",
        "  data_transform_simple=transforms.Compose(\n",
        "    [transforms.Resize((228,228))])\n",
        "\n",
        "  image=data_transform_simple(convertion_function(path0))\n",
        "  image=image.unsqueeze(0)\n",
        "\n",
        "\n",
        "  device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  load_path=Path(\"/content/models/MODEL_PATH222\")\n",
        "\n",
        "\n",
        "  load_model=model_creator.tinygvv(3,4,hidden_unit1,hidden_unit2,hidden_unit3,hidden_unit4,hidden_unit5,8).to(device)\n",
        "\n",
        "\n",
        "  load_model.load_state_dict(torch.load(f=load_path,map_location=torch.device('cpu')))\n",
        "\n",
        "  load_model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    y_logit=load_model(image)\n",
        "\n",
        "    y_label=torch.softmax(y_logit,-1).argmax(-1)\n",
        "\n",
        "  return y_label.item()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print (custom_loader())\n",
        "\n"
      ],
      "metadata": {
        "id": "YwfMy7GVBKwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d797a60-d434-4f3e-ef0b-2c520dadd52d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing out_model_set/final_pred.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/SartajBhuvaji/Brain-Tumor-Classification-DataSet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bgHGyOcqmpz",
        "outputId": "905fdb36-1847-4a88-b551-8a2f8dc831bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Brain-Tumor-Classification-DataSet'...\n",
            "remote: Enumerating objects: 3039, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 3039 (delta 0), reused 0 (delta 0), pack-reused 3035\u001b[K\n",
            "Receiving objects: 100% (3039/3039), 79.25 MiB | 23.03 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python open_test_2.py"
      ],
      "metadata": {
        "id": "8hAjcrXFqnTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python out_model_set/final_train.py --NUM_EPOCHS 10 --hidden_unit1 64 --hidden_unit2  32 --hidden_unit3 32 --hidden_unit4 16  --hidden_unit5 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxctAqBppZeN",
        "outputId": "169d291f-56c3-4336-bae6-10ecfd4daac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_loss : 1.3314551141526965, training_acc : 0.33892045454545455,testing_loss : 1.503663494036748, testing_acc : 0.3158653846153846\n",
            "training_loss : 1.110103189945221, training_acc : 0.5255050505050505,testing_loss : 1.6750275217569792, testing_acc : 0.2846153846153846\n",
            "training_loss : 1.021781512763765, training_acc : 0.5612373737373737,testing_loss : 1.7128104063180776, testing_acc : 0.38173076923076926\n",
            "training_loss : 0.9346505019399854, training_acc : 0.607070707070707,testing_loss : 1.6445526022177477, testing_acc : 0.4096153846153846\n",
            "training_loss : 0.8370787786112891, training_acc : 0.661395202020202,testing_loss : 1.649495358650501, testing_acc : 0.45528846153846153\n",
            "training_loss : 0.7935474978552924, training_acc : 0.677020202020202,testing_loss : 1.8635942935943604, testing_acc : 0.47259615384615383\n",
            "training_loss : 0.7612521065606012, training_acc : 0.6919823232323232,testing_loss : 1.4148603677749634, testing_acc : 0.5177884615384616\n",
            "training_loss : 0.7071084171533585, training_acc : 0.7169191919191918,testing_loss : 1.397462322161748, testing_acc : 0.541826923076923\n",
            "training_loss : 0.6685388230615192, training_acc : 0.7320391414141415,testing_loss : 1.5905444392791162, testing_acc : 0.5394230769230769\n",
            "training_loss : 0.6371903469165167, training_acc : 0.746780303030303,testing_loss : 1.779738527077895, testing_acc : 0.583173076923077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python out_model_set/final_pred.py  --hidden_unit1 64 --hidden_unit2  32 --hidden_unit3 32 --hidden_unit4 16  --hidden_unit5 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfL_FqHQame_",
        "outputId": "e9dab91a-293d-48f9-acfb-f979b1344d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python out_model_set/final_pred.py  --imagepath \"Testing/pituitary_tumor/image(54).jpg\" --hidden_unit1 64 --hidden_unit2  32 --hidden_unit3 32 --hidden_unit4 16  --hidden_unit5 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsRdvAfnEkqe",
        "outputId": "f48d6203-90f1-4f3e-febb-ac32289e5bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import torchvision\n",
        "\n",
        "print (torchvision.__version__,torch.__version__)"
      ],
      "metadata": {
        "id": "ACLYcEmdUewT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6969e9-4499-463e-b1de-c7794e3fd812"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18.0+cu121 2.3.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from out_model_set import data_creator,model_creator,train_creator\n",
        "\n"
      ],
      "metadata": {
        "id": "i5zNIR_f-g51"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nkwnPrGl_Osu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}